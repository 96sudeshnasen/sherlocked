{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu relu relu lr:0.35\n",
      "1 864.5455937159131\n",
      "Iteration: 1,Layer \n",
      "total number of negative weights in final layer:\n",
      "1441/2560\n",
      "2 594.3029355729359\n",
      "Iteration: 2,Layer \n",
      "total number of negative weights in final layer:\n",
      "1746/2560\n",
      "3 499.31785141518776\n",
      "Iteration: 3,Layer \n",
      "total number of negative weights in final layer:\n",
      "1864/2560\n",
      "4 1085.3895363934948\n",
      "Iteration: 4,Layer \n",
      "total number of negative weights in final layer:\n",
      "2071/2560\n",
      "5 4303.666893005371\n",
      "Iteration: 5,Layer \n",
      "total number of negative weights in final layer:\n",
      "2085/2560\n",
      "6 4314.121509075165\n",
      "Iteration: 6,Layer \n",
      "total number of negative weights in final layer:\n",
      "2087/2560\n",
      "7 4317.130795240402\n",
      "Iteration: 7,Layer \n",
      "total number of negative weights in final layer:\n",
      "2087/2560\n",
      "8 4317.130795240402\n",
      "Iteration: 8,Layer \n",
      "total number of negative weights in final layer:\n",
      "2087/2560\n",
      "9 4317.130795240402\n",
      "Iteration: 9,Layer \n",
      "total number of negative weights in final layer:\n",
      "2087/2560\n",
      "10 4317.130795240402\n",
      "Iteration: 10,Layer \n",
      "total number of negative weights in final layer:\n",
      "2087/2560\n",
      "\n",
      "Test set: Average loss: 2.3026, Accuracy: 980/10000 (10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "relu relu relu lr:0.65\n",
      "1 4315.789119839668\n",
      "Iteration: 1,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "2 4317.346662282944\n",
      "Iteration: 2,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "3 4317.346662282944\n",
      "Iteration: 3,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "4 4317.346662282944\n",
      "Iteration: 4,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "5 4317.346662282944\n",
      "Iteration: 5,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "6 4317.346662282944\n",
      "Iteration: 6,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "7 4317.346662282944\n",
      "Iteration: 7,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "8 4317.346662282944\n",
      "Iteration: 8,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "9 4317.346662282944\n",
      "Iteration: 9,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "10 4317.346662282944\n",
      "Iteration: 10,Layer \n",
      "total number of negative weights in final layer:\n",
      "1453/2560\n",
      "\n",
      "Test set: Average loss: 2.3026, Accuracy: 980/10000 (10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "relu relu relu lr:0.75\n",
      "1 4318.356650590897\n",
      "Iteration: 1,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "2 4317.346662282944\n",
      "Iteration: 2,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "3 4317.346662282944\n",
      "Iteration: 3,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "4 4317.346662282944\n",
      "Iteration: 4,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "5 4317.346662282944\n",
      "Iteration: 5,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "6 4317.346662282944\n",
      "Iteration: 6,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "7 4317.346662282944\n",
      "Iteration: 7,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "8 4317.346662282944\n",
      "Iteration: 8,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "9 4317.346662282944\n",
      "Iteration: 9,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "10 4317.346662282944\n",
      "Iteration: 10,Layer \n",
      "total number of negative weights in final layer:\n",
      "1520/2560\n",
      "\n",
      "Test set: Average loss: 2.3026, Accuracy: 980/10000 (10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "relu relu relu lr:0.85\n",
      "1 4321.906678199768\n",
      "Iteration: 1,Layer \n",
      "total number of negative weights in final layer:\n",
      "1627/2560\n",
      "2 4317.930245399475\n",
      "Iteration: 2,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "3 4317.346673965454\n",
      "Iteration: 3,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "4 4317.346662282944\n",
      "Iteration: 4,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "5 4317.346662282944\n",
      "Iteration: 5,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "6 4317.346662282944\n",
      "Iteration: 6,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "7 4317.346662282944\n",
      "Iteration: 7,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "8 4317.346662282944\n",
      "Iteration: 8,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "9 4317.346662282944\n",
      "Iteration: 9,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "10 4317.346662282944\n",
      "Iteration: 10,Layer \n",
      "total number of negative weights in final layer:\n",
      "1655/2560\n",
      "\n",
      "Test set: Average loss: 2.3026, Accuracy: 980/10000 (10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "relu relu relu lr:0.95\n",
      "1 4320.0475018024445\n",
      "Iteration: 1,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "2 4317.346662282944\n",
      "Iteration: 2,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "3 4317.346662282944\n",
      "Iteration: 3,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "4 4317.346662282944\n",
      "Iteration: 4,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "5 4317.346662282944\n",
      "Iteration: 5,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "6 4317.346662282944\n",
      "Iteration: 6,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "7 4317.346662282944\n",
      "Iteration: 7,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "8 4317.346662282944\n",
      "Iteration: 8,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "9 4317.346662282944\n",
      "Iteration: 9,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "10 4317.346662282944\n",
      "Iteration: 10,Layer \n",
      "total number of negative weights in final layer:\n",
      "1521/2560\n",
      "\n",
      "Test set: Average loss: 2.3026, Accuracy: 980/10000 (10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "test_batch_size = 1000\n",
    "epochs = 10\n",
    "momentum = 0.5\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "class MLPNetModified(nn.Module):\n",
    "    def __init__(self, f1, f2, f3):\n",
    "        super(MLPNetModified, self).__init__()\n",
    "        self.f1 = f1\n",
    "        self.f2 = f2\n",
    "        self.f3 = f3\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        half = int(len(x[0])/2)\n",
    "        first_part = x[:, 0:half]\n",
    "        second_part = x[:, half:]\n",
    "        first_part = self.f1(first_part)\n",
    "        second_part = self.f1(second_part)\n",
    "        x = torch.cat((first_part, second_part), 1)\n",
    "        x = self.fc2(x)\n",
    "        half = int(len(x[0])/2)\n",
    "        first_part = x[:, 0:half]\n",
    "        second_part = x[:, half:]\n",
    "        first_part = self.f2(first_part)\n",
    "        second_part = self.f2(second_part)\n",
    "        x = torch.cat((first_part, second_part), 1)\n",
    "        x = self.fc3(x)\n",
    "        half = int(len(x[0])/2)\n",
    "        first_part = x[:, 0:half]\n",
    "        second_part = x[:, half:]\n",
    "        first_part = self.f3(first_part)\n",
    "        second_part = self.f3(second_part)\n",
    "        x = torch.cat((first_part, second_part), 1)\n",
    "        return F.log_softmax(x)\n",
    "    def name(self):\n",
    "        return 'mlpnet'\n",
    "\n",
    "def solve(f1, f2, f3 ,lr):\n",
    "    print (str(f1).split()[1], str(f2).split()[1], str(f3).split()[1], \"lr:\"+str(lr))\n",
    "    model = MLPNetModified(f1, f2, f3)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    train_loss = []\n",
    "    test_losses = []\n",
    "    test_accuracy = []\n",
    "    parameters_list = []\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        loss_to_print = 0\n",
    "        for data, target in train_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_to_print += loss.data[0]\n",
    "                # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                #     epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                #     100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "        train_loss.append(loss_to_print)\n",
    "        print (epoch, loss_to_print)\n",
    "        p= model.state_dict() \n",
    "        arr=p['fc3.weight'].numpy()\n",
    "        print(\"Iteration: {},Layer \".format(epoch))\n",
    "        print(\"total number of negative weights in final layer:\")\n",
    "        print(\"{}/{}\".format((arr <= 0).sum(),arr.size))\n",
    "#         print(weights(p))\n",
    "        return train_loss\n",
    "    def test(epoch):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        if (epoch == epochs):\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                100. * correct / len(test_loader.dataset)))\n",
    "            print(\"--------------------------------------------------------------------------------\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy.append(100. * correct / len(test_loader.dataset))\n",
    "        return test_losses\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        TRAIN_LOSS = train(epoch)\n",
    "        TEST_LOSS  = test(epoch)\n",
    "    return TRAIN_LOSS,TEST_LOSS,parameters_list\n",
    "\n",
    "# train_plots_sig = [[]]*20\n",
    "# test_plots_sig = [[]]*20\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(1, 21,2):\n",
    "#     train_plots_sig[i-1],test_plots_sig[i-1] = solve(F.sigmoid, F.sigmoid, F.sigmoid, 0.05 *i)\n",
    "#     plt.plot(train_plots_sig[i-1],label = \"lr_\"+str(0.05*i))\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.savefig(\"training_convergence_sig_sig_sig.png\")\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(1, 21, 2):\n",
    "#     plt.plot(test_plots_sig[i-1],label = \"lr_\"+str(0.05*i))\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.savefig(\"test_convergence_sig_sig_sig.png\")\n",
    "\n",
    "\n",
    "\n",
    "# train_plots_relu = [[]]*20\n",
    "# test_plots_relu  = [[]]*20\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(1, 21,2):\n",
    "#     train_plots_relu[i-1],test_plots_relu[i-1] = solve(F.relu, F.relu, F.relu, 0.05 *i)\n",
    "#     plt.plot(train_plots_relu[i-1],label = \"lr_\"+str(0.05*i))\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.savefig(\"training_convergence_relu_relu_relu.png\")\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(1, 21, 2):\n",
    "#     plt.plot(test_plots_relu[i-1],label = \"lr_\"+str(0.05*i))\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.savefig(\"test_convergence_relu_relu_relu.png\")\n",
    "\n",
    "train_plots_relu0, test_plots_relu0, parameters0 = solve(F.relu, F.relu, F.relu, 0.35)\n",
    "train_plots_relu1, test_plots_relu1, parameters1 = solve(F.relu, F.relu, F.relu, 0.65)\n",
    "train_plots_relu2, test_plots_relu2, parameters2 = solve(F.relu, F.relu, F.relu, 0.75)\n",
    "train_plots_relu3, test_plots_relu3, parameters3 = solve(F.relu, F.relu, F.relu, 0.85)\n",
    "train_plots_relu4, test_plots_relu4, parameters4 = solve(F.relu, F.relu, F.relu, 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
